<!DOCTYPE html>
<!-- saved from url=(0014)about:internet -->
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
<meta http-equiv="x-ua-compatible" content="IE=9" >

<title>Tree Models</title>

<style type="text/css">
body, td {
   font-family: sans-serif;
   background-color: white;
   font-size: 12px;
   margin: 8px;
}

tt, code, pre {
   font-family: 'DejaVu Sans Mono', 'Droid Sans Mono', 'Lucida Console', Consolas, Monaco, monospace;
}

h1 { 
   font-size:2.2em; 
}

h2 { 
   font-size:1.8em; 
}

h3 { 
   font-size:1.4em; 
}

h4 { 
   font-size:1.0em; 
}

h5 { 
   font-size:0.9em; 
}

h6 { 
   font-size:0.8em; 
}

a:visited {
   color: rgb(50%, 0%, 50%);
}

pre {	
   margin-top: 0;
   max-width: 95%;
   border: 1px solid #ccc;
   white-space: pre-wrap;
}

pre code {
   display: block; padding: 0.5em;
}

code.r, code.cpp {
   background-color: #F8F8F8;
}

table, td, th {
  border: none;
}

blockquote {
   color:#666666;
   margin:0;
   padding-left: 1em;
   border-left: 0.5em #EEE solid;
}

hr {
   height: 0px;
   border-bottom: none;
   border-top-width: thin;
   border-top-style: dotted;
   border-top-color: #999999;
}

@media print {
   * { 
      background: transparent !important; 
      color: black !important; 
      filter:none !important; 
      -ms-filter: none !important; 
   }

   body { 
      font-size:12pt; 
      max-width:100%; 
   }
       
   a, a:visited { 
      text-decoration: underline; 
   }

   hr { 
      visibility: hidden;
      page-break-before: always;
   }

   pre, blockquote { 
      padding-right: 1em; 
      page-break-inside: avoid; 
   }

   tr, img { 
      page-break-inside: avoid; 
   }

   img { 
      max-width: 100% !important; 
   }

   @page :left { 
      margin: 15mm 20mm 15mm 10mm; 
   }
     
   @page :right { 
      margin: 15mm 10mm 15mm 20mm; 
   }

   p, h2, h3 { 
      orphans: 3; widows: 3; 
   }

   h2, h3 { 
      page-break-after: avoid; 
   }
}

</style>

<!-- Styles for R syntax highlighter -->
<style type="text/css">
   pre .operator,
   pre .paren {
     color: rgb(104, 118, 135)
   }

   pre .literal {
     color: rgb(88, 72, 246)
   }

   pre .number {
     color: rgb(0, 0, 205);
   }

   pre .comment {
     color: rgb(76, 136, 107);
   }

   pre .keyword {
     color: rgb(0, 0, 255);
   }

   pre .identifier {
     color: rgb(0, 0, 0);
   }

   pre .string {
     color: rgb(3, 106, 7);
   }
</style>

<!-- R syntax highlighter -->
<script type="text/javascript">
var hljs=new function(){function m(p){return p.replace(/&/gm,"&amp;").replace(/</gm,"&lt;")}function f(r,q,p){return RegExp(q,"m"+(r.cI?"i":"")+(p?"g":""))}function b(r){for(var p=0;p<r.childNodes.length;p++){var q=r.childNodes[p];if(q.nodeName=="CODE"){return q}if(!(q.nodeType==3&&q.nodeValue.match(/\s+/))){break}}}function h(t,s){var p="";for(var r=0;r<t.childNodes.length;r++){if(t.childNodes[r].nodeType==3){var q=t.childNodes[r].nodeValue;if(s){q=q.replace(/\n/g,"")}p+=q}else{if(t.childNodes[r].nodeName=="BR"){p+="\n"}else{p+=h(t.childNodes[r])}}}if(/MSIE [678]/.test(navigator.userAgent)){p=p.replace(/\r/g,"\n")}return p}function a(s){var r=s.className.split(/\s+/);r=r.concat(s.parentNode.className.split(/\s+/));for(var q=0;q<r.length;q++){var p=r[q].replace(/^language-/,"");if(e[p]){return p}}}function c(q){var p=[];(function(s,t){for(var r=0;r<s.childNodes.length;r++){if(s.childNodes[r].nodeType==3){t+=s.childNodes[r].nodeValue.length}else{if(s.childNodes[r].nodeName=="BR"){t+=1}else{if(s.childNodes[r].nodeType==1){p.push({event:"start",offset:t,node:s.childNodes[r]});t=arguments.callee(s.childNodes[r],t);p.push({event:"stop",offset:t,node:s.childNodes[r]})}}}}return t})(q,0);return p}function k(y,w,x){var q=0;var z="";var s=[];function u(){if(y.length&&w.length){if(y[0].offset!=w[0].offset){return(y[0].offset<w[0].offset)?y:w}else{return w[0].event=="start"?y:w}}else{return y.length?y:w}}function t(D){var A="<"+D.nodeName.toLowerCase();for(var B=0;B<D.attributes.length;B++){var C=D.attributes[B];A+=" "+C.nodeName.toLowerCase();if(C.value!==undefined&&C.value!==false&&C.value!==null){A+='="'+m(C.value)+'"'}}return A+">"}while(y.length||w.length){var v=u().splice(0,1)[0];z+=m(x.substr(q,v.offset-q));q=v.offset;if(v.event=="start"){z+=t(v.node);s.push(v.node)}else{if(v.event=="stop"){var p,r=s.length;do{r--;p=s[r];z+=("</"+p.nodeName.toLowerCase()+">")}while(p!=v.node);s.splice(r,1);while(r<s.length){z+=t(s[r]);r++}}}}return z+m(x.substr(q))}function j(){function q(x,y,v){if(x.compiled){return}var u;var s=[];if(x.k){x.lR=f(y,x.l||hljs.IR,true);for(var w in x.k){if(!x.k.hasOwnProperty(w)){continue}if(x.k[w] instanceof Object){u=x.k[w]}else{u=x.k;w="keyword"}for(var r in u){if(!u.hasOwnProperty(r)){continue}x.k[r]=[w,u[r]];s.push(r)}}}if(!v){if(x.bWK){x.b="\\b("+s.join("|")+")\\s"}x.bR=f(y,x.b?x.b:"\\B|\\b");if(!x.e&&!x.eW){x.e="\\B|\\b"}if(x.e){x.eR=f(y,x.e)}}if(x.i){x.iR=f(y,x.i)}if(x.r===undefined){x.r=1}if(!x.c){x.c=[]}x.compiled=true;for(var t=0;t<x.c.length;t++){if(x.c[t]=="self"){x.c[t]=x}q(x.c[t],y,false)}if(x.starts){q(x.starts,y,false)}}for(var p in e){if(!e.hasOwnProperty(p)){continue}q(e[p].dM,e[p],true)}}function d(B,C){if(!j.called){j();j.called=true}function q(r,M){for(var L=0;L<M.c.length;L++){if((M.c[L].bR.exec(r)||[null])[0]==r){return M.c[L]}}}function v(L,r){if(D[L].e&&D[L].eR.test(r)){return 1}if(D[L].eW){var M=v(L-1,r);return M?M+1:0}return 0}function w(r,L){return L.i&&L.iR.test(r)}function K(N,O){var M=[];for(var L=0;L<N.c.length;L++){M.push(N.c[L].b)}var r=D.length-1;do{if(D[r].e){M.push(D[r].e)}r--}while(D[r+1].eW);if(N.i){M.push(N.i)}return f(O,M.join("|"),true)}function p(M,L){var N=D[D.length-1];if(!N.t){N.t=K(N,E)}N.t.lastIndex=L;var r=N.t.exec(M);return r?[M.substr(L,r.index-L),r[0],false]:[M.substr(L),"",true]}function z(N,r){var L=E.cI?r[0].toLowerCase():r[0];var M=N.k[L];if(M&&M instanceof Array){return M}return false}function F(L,P){L=m(L);if(!P.k){return L}var r="";var O=0;P.lR.lastIndex=0;var M=P.lR.exec(L);while(M){r+=L.substr(O,M.index-O);var N=z(P,M);if(N){x+=N[1];r+='<span class="'+N[0]+'">'+M[0]+"</span>"}else{r+=M[0]}O=P.lR.lastIndex;M=P.lR.exec(L)}return r+L.substr(O,L.length-O)}function J(L,M){if(M.sL&&e[M.sL]){var r=d(M.sL,L);x+=r.keyword_count;return r.value}else{return F(L,M)}}function I(M,r){var L=M.cN?'<span class="'+M.cN+'">':"";if(M.rB){y+=L;M.buffer=""}else{if(M.eB){y+=m(r)+L;M.buffer=""}else{y+=L;M.buffer=r}}D.push(M);A+=M.r}function G(N,M,Q){var R=D[D.length-1];if(Q){y+=J(R.buffer+N,R);return false}var P=q(M,R);if(P){y+=J(R.buffer+N,R);I(P,M);return P.rB}var L=v(D.length-1,M);if(L){var O=R.cN?"</span>":"";if(R.rE){y+=J(R.buffer+N,R)+O}else{if(R.eE){y+=J(R.buffer+N,R)+O+m(M)}else{y+=J(R.buffer+N+M,R)+O}}while(L>1){O=D[D.length-2].cN?"</span>":"";y+=O;L--;D.length--}var r=D[D.length-1];D.length--;D[D.length-1].buffer="";if(r.starts){I(r.starts,"")}return R.rE}if(w(M,R)){throw"Illegal"}}var E=e[B];var D=[E.dM];var A=0;var x=0;var y="";try{var s,u=0;E.dM.buffer="";do{s=p(C,u);var t=G(s[0],s[1],s[2]);u+=s[0].length;if(!t){u+=s[1].length}}while(!s[2]);if(D.length>1){throw"Illegal"}return{r:A,keyword_count:x,value:y}}catch(H){if(H=="Illegal"){return{r:0,keyword_count:0,value:m(C)}}else{throw H}}}function g(t){var p={keyword_count:0,r:0,value:m(t)};var r=p;for(var q in e){if(!e.hasOwnProperty(q)){continue}var s=d(q,t);s.language=q;if(s.keyword_count+s.r>r.keyword_count+r.r){r=s}if(s.keyword_count+s.r>p.keyword_count+p.r){r=p;p=s}}if(r.language){p.second_best=r}return p}function i(r,q,p){if(q){r=r.replace(/^((<[^>]+>|\t)+)/gm,function(t,w,v,u){return w.replace(/\t/g,q)})}if(p){r=r.replace(/\n/g,"<br>")}return r}function n(t,w,r){var x=h(t,r);var v=a(t);var y,s;if(v){y=d(v,x)}else{return}var q=c(t);if(q.length){s=document.createElement("pre");s.innerHTML=y.value;y.value=k(q,c(s),x)}y.value=i(y.value,w,r);var u=t.className;if(!u.match("(\\s|^)(language-)?"+v+"(\\s|$)")){u=u?(u+" "+v):v}if(/MSIE [678]/.test(navigator.userAgent)&&t.tagName=="CODE"&&t.parentNode.tagName=="PRE"){s=t.parentNode;var p=document.createElement("div");p.innerHTML="<pre><code>"+y.value+"</code></pre>";t=p.firstChild.firstChild;p.firstChild.cN=s.cN;s.parentNode.replaceChild(p.firstChild,s)}else{t.innerHTML=y.value}t.className=u;t.result={language:v,kw:y.keyword_count,re:y.r};if(y.second_best){t.second_best={language:y.second_best.language,kw:y.second_best.keyword_count,re:y.second_best.r}}}function o(){if(o.called){return}o.called=true;var r=document.getElementsByTagName("pre");for(var p=0;p<r.length;p++){var q=b(r[p]);if(q){n(q,hljs.tabReplace)}}}function l(){if(window.addEventListener){window.addEventListener("DOMContentLoaded",o,false);window.addEventListener("load",o,false)}else{if(window.attachEvent){window.attachEvent("onload",o)}else{window.onload=o}}}var e={};this.LANGUAGES=e;this.highlight=d;this.highlightAuto=g;this.fixMarkup=i;this.highlightBlock=n;this.initHighlighting=o;this.initHighlightingOnLoad=l;this.IR="[a-zA-Z][a-zA-Z0-9_]*";this.UIR="[a-zA-Z_][a-zA-Z0-9_]*";this.NR="\\b\\d+(\\.\\d+)?";this.CNR="\\b(0[xX][a-fA-F0-9]+|(\\d+(\\.\\d*)?|\\.\\d+)([eE][-+]?\\d+)?)";this.BNR="\\b(0b[01]+)";this.RSR="!|!=|!==|%|%=|&|&&|&=|\\*|\\*=|\\+|\\+=|,|\\.|-|-=|/|/=|:|;|<|<<|<<=|<=|=|==|===|>|>=|>>|>>=|>>>|>>>=|\\?|\\[|\\{|\\(|\\^|\\^=|\\||\\|=|\\|\\||~";this.ER="(?![\\s\\S])";this.BE={b:"\\\\.",r:0};this.ASM={cN:"string",b:"'",e:"'",i:"\\n",c:[this.BE],r:0};this.QSM={cN:"string",b:'"',e:'"',i:"\\n",c:[this.BE],r:0};this.CLCM={cN:"comment",b:"//",e:"$"};this.CBLCLM={cN:"comment",b:"/\\*",e:"\\*/"};this.HCM={cN:"comment",b:"#",e:"$"};this.NM={cN:"number",b:this.NR,r:0};this.CNM={cN:"number",b:this.CNR,r:0};this.BNM={cN:"number",b:this.BNR,r:0};this.inherit=function(r,s){var p={};for(var q in r){p[q]=r[q]}if(s){for(var q in s){p[q]=s[q]}}return p}}();hljs.LANGUAGES.cpp=function(){var a={keyword:{"false":1,"int":1,"float":1,"while":1,"private":1,"char":1,"catch":1,"export":1,virtual:1,operator:2,sizeof:2,dynamic_cast:2,typedef:2,const_cast:2,"const":1,struct:1,"for":1,static_cast:2,union:1,namespace:1,unsigned:1,"long":1,"throw":1,"volatile":2,"static":1,"protected":1,bool:1,template:1,mutable:1,"if":1,"public":1,friend:2,"do":1,"return":1,"goto":1,auto:1,"void":2,"enum":1,"else":1,"break":1,"new":1,extern:1,using:1,"true":1,"class":1,asm:1,"case":1,typeid:1,"short":1,reinterpret_cast:2,"default":1,"double":1,register:1,explicit:1,signed:1,typename:1,"try":1,"this":1,"switch":1,"continue":1,wchar_t:1,inline:1,"delete":1,alignof:1,char16_t:1,char32_t:1,constexpr:1,decltype:1,noexcept:1,nullptr:1,static_assert:1,thread_local:1,restrict:1,_Bool:1,complex:1},built_in:{std:1,string:1,cin:1,cout:1,cerr:1,clog:1,stringstream:1,istringstream:1,ostringstream:1,auto_ptr:1,deque:1,list:1,queue:1,stack:1,vector:1,map:1,set:1,bitset:1,multiset:1,multimap:1,unordered_set:1,unordered_map:1,unordered_multiset:1,unordered_multimap:1,array:1,shared_ptr:1}};return{dM:{k:a,i:"</",c:[hljs.CLCM,hljs.CBLCLM,hljs.QSM,{cN:"string",b:"'\\\\?.",e:"'",i:"."},{cN:"number",b:"\\b(\\d+(\\.\\d*)?|\\.\\d+)(u|U|l|L|ul|UL|f|F)"},hljs.CNM,{cN:"preprocessor",b:"#",e:"$"},{cN:"stl_container",b:"\\b(deque|list|queue|stack|vector|map|set|bitset|multiset|multimap|unordered_map|unordered_set|unordered_multiset|unordered_multimap|array)\\s*<",e:">",k:a,r:10,c:["self"]}]}}}();hljs.LANGUAGES.r={dM:{c:[hljs.HCM,{cN:"number",b:"\\b0[xX][0-9a-fA-F]+[Li]?\\b",e:hljs.IMMEDIATE_RE,r:0},{cN:"number",b:"\\b\\d+(?:[eE][+\\-]?\\d*)?L\\b",e:hljs.IMMEDIATE_RE,r:0},{cN:"number",b:"\\b\\d+\\.(?!\\d)(?:i\\b)?",e:hljs.IMMEDIATE_RE,r:1},{cN:"number",b:"\\b\\d+(?:\\.\\d*)?(?:[eE][+\\-]?\\d*)?i?\\b",e:hljs.IMMEDIATE_RE,r:0},{cN:"number",b:"\\.\\d+(?:[eE][+\\-]?\\d*)?i?\\b",e:hljs.IMMEDIATE_RE,r:1},{cN:"keyword",b:"(?:tryCatch|library|setGeneric|setGroupGeneric)\\b",e:hljs.IMMEDIATE_RE,r:10},{cN:"keyword",b:"\\.\\.\\.",e:hljs.IMMEDIATE_RE,r:10},{cN:"keyword",b:"\\.\\.\\d+(?![\\w.])",e:hljs.IMMEDIATE_RE,r:10},{cN:"keyword",b:"\\b(?:function)",e:hljs.IMMEDIATE_RE,r:2},{cN:"keyword",b:"(?:if|in|break|next|repeat|else|for|return|switch|while|try|stop|warning|require|attach|detach|source|setMethod|setClass)\\b",e:hljs.IMMEDIATE_RE,r:1},{cN:"literal",b:"(?:NA|NA_integer_|NA_real_|NA_character_|NA_complex_)\\b",e:hljs.IMMEDIATE_RE,r:10},{cN:"literal",b:"(?:NULL|TRUE|FALSE|T|F|Inf|NaN)\\b",e:hljs.IMMEDIATE_RE,r:1},{cN:"identifier",b:"[a-zA-Z.][a-zA-Z0-9._]*\\b",e:hljs.IMMEDIATE_RE,r:0},{cN:"operator",b:"<\\-(?!\\s*\\d)",e:hljs.IMMEDIATE_RE,r:2},{cN:"operator",b:"\\->|<\\-",e:hljs.IMMEDIATE_RE,r:1},{cN:"operator",b:"%%|~",e:hljs.IMMEDIATE_RE},{cN:"operator",b:">=|<=|==|!=|\\|\\||&&|=|\\+|\\-|\\*|/|\\^|>|<|!|&|\\||\\$|:",e:hljs.IMMEDIATE_RE,r:0},{cN:"operator",b:"%",e:"%",i:"\\n",r:1},{cN:"identifier",b:"`",e:"`",r:0},{cN:"string",b:'"',e:'"',c:[hljs.BE],r:0},{cN:"string",b:"'",e:"'",c:[hljs.BE],r:0},{cN:"paren",b:"[[({\\])}]",e:hljs.IMMEDIATE_RE,r:0}]}};
hljs.initHighlightingOnLoad();
</script>


<!-- MathJax scripts -->
<script type="text/javascript" src="https://c328740.ssl.cf1.rackcdn.com/mathjax/2.0-latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>



</head>

<body>
<h1>Tree Models</h1>

<p>In this lab we will go through the model building, validation, and interpretation of tree models. The focus will be on <em>rpart</em> package.</p>

<h2>Regression Tree vs. Classification Tree</h2>

<p>CART stands for classification and regression tree. </p>

<ul>
<li>Regression tree: response variable Y is numerical</li>
<li>Classification tree: response variable Y is categorical</li>
</ul>

<p>For the regression tree example, we will use the Boston Housing data. Recall the response variable is the housing price. For the classification tree example, we will use the credit scoring data. The response variable is whether the loan went to default.</p>

<p>Note that unlkie logistic regreesion, the response variable does not have to be binary in case of classification tree. We can use classification tree on classification problems with more than 2 outcomes.</p>

<p>Let us load the data sets. This time the training and test datasets are divided for you so we can get similar answers,</p>

<pre><code class="r">boston.data = read.csv(&quot;http://homepages.uc.edu/~maifg/7040/boston.csv&quot;)
boston.train = read.csv(&quot;http://homepages.uc.edu/~maifg/7040/boston.train.csv&quot;)
boston.test = read.csv(&quot;http://homepages.uc.edu/~maifg/7040/boston.test.csv&quot;)

credit.data = read.csv(&quot;http://homepages.uc.edu/~maifg/7040/credit0.csv&quot;)
credit.train = read.csv(&quot;http://homepages.uc.edu/~maifg/7040/credit.train.csv&quot;)
credit.test = read.csv(&quot;http://homepages.uc.edu/~maifg/7040/credit.test.csv&quot;)
</code></pre>

<p>We will use the &#39;rpart&#39; library.</p>

<pre><code class="r">install.packages(&quot;rpart&quot;)
</code></pre>

<pre><code class="r">library(rpart)
</code></pre>

<h2>Fitting Models and Prediction</h2>

<h3>Fitting regression tree</h3>

<p>The simple form of the <em>rpart</em> function is similar to <em>lm</em> and <em>glm</em>. It takes a formula argument in which you specify the response and predictor variables, and a data argument in which you specify the data frame.</p>

<pre><code class="r">boston.rpart &lt;- rpart(formula = medv ~ ., data = boston.train)
</code></pre>

<h4>Printing and ploting the tree</h4>

<pre><code class="r">boston.rpart
</code></pre>

<pre><code>## n= 455 
## 
## node), split, n, deviance, yval
##       * denotes terminal node
## 
##  1) root 455 39645.6100 22.60835  
##    2) rm&lt; 6.9715 390 16846.5000 20.04077  
##      4) lstat&gt;=14.4 160  3066.1440 14.88313  
##        8) crim&gt;=6.99237 70  1025.6890 12.02429 *
##        9) crim&lt; 6.99237 90  1023.3760 17.10667 *
##      5) lstat&lt; 14.4 230  6563.3110 23.62870  
##       10) lstat&gt;=4.91 209  4036.4450 22.78373  
##         20) lstat&gt;=9.95 94   631.5261 20.71596 *
##         21) lstat&lt; 9.95 115  2674.4820 24.47391  
##           42) age&lt; 89.45 107  1225.9660 23.85327 *
##           43) age&gt;=89.45 8   856.0350 32.77500 *
##       11) lstat&lt; 4.91 21   892.5695 32.03810 *
##    3) rm&gt;=6.9715 65  4801.6380 38.01385  
##      6) rm&lt; 7.437 36  1224.8090 32.44444 *
##      7) rm&gt;=7.437 29  1073.9780 44.92759 *
</code></pre>

<pre><code class="r">plot(boston.rpart)
text(boston.rpart, pretty = TRUE)
</code></pre>

<p><img src="data:image/png;base64,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" alt="plot of chunk unnamed-chunk-6"/> </p>

<h4>Prediction using regression tree</h4>

<p>The in-sample and out-of-sample prediction for regression tree is also similar to <em>lm</em> and <em>glm</em> models.</p>

<p>In-sample prediction</p>

<pre><code class="r">boston.train.pred.tree = predict(boston.rpart)
</code></pre>

<p>Out-of-sample prediction</p>

<pre><code class="r">boston.test.pred.tree = predict(boston.rpart, boston.test)
</code></pre>

<p>The mean squred error loss for this tree model is</p>

<pre><code class="r">mean((boston.test.pred.tree - boston.test$medv)^2)
</code></pre>

<pre><code>## [1] 14.35141
</code></pre>

<p>We can compare this model&#39;s out-of-sample performance with the linear regression model with all variables in it.</p>

<pre><code class="r">boston.reg = lm(medv ~ ., data = boston.train)
boston.test.pred.reg = predict(boston.reg, boston.test)
mean((boston.test.pred.reg - boston.test$medv)^2)
</code></pre>

<pre><code>## [1] 18.88389
</code></pre>

<h3>Fitting classification tree (when you know the cost function)</h3>

<p>The classification tree is slightly more complicated to specify. What makes it more complicated is that we often have asymmetric cost function. In the credit scoring case it means that false negatives (predicting 0 when truth is 1, or giving out loans that end up in default) will cost more than false positives (predicting 1 when truth is 0, rejecting loans that you should not reject).</p>

<p>Here we make the assumption that false negative cost 10 times of false positive. In real life the cost structure should be carefully researched.</p>

<pre><code class="r">credit.rpart &lt;- rpart(formula = Y ~ . - id, data = credit.train, method = &quot;class&quot;, 
    parms = list(loss = matrix(c(0, 10, 1, 0), nrow = 2)))
</code></pre>

<p>Note the following important differences from the regression tree:</p>

<ul>
<li><p>The method = &ldquo;class&rdquo; is required if the response is not declared as factors.</p></li>
<li><p>The parms argument, which is a list. The most import element is the loss matrix. The diagonal elements are 0, and off-diagonal elements tells you the loss(cost) of classifying something wrong. For binary classification, the numbers in c() specify the cost in this sequence: c(0, False Negative, False Positive, 0).
If you have symmetric cost, you can ignore the parms argument.</p></li>
</ul>

<p>For more advanced controls, you should carefully read the help document for the rpart function.</p>

<h4>Printing and ploting the tree</h4>

<pre><code class="r">credit.rpart
</code></pre>

<pre><code>## n= 4500 
## 
## node), split, n, loss, yval, (yprob)
##       * denotes terminal node
## 
##   1) root 4500 2760 0 (0.93866667 0.06133333)  
##     2) X9&gt;=-0.2105 898    0 0 (1.00000000 0.00000000) *
##     3) X9&lt; -0.2105 3602 2760 0 (0.92337590 0.07662410)  
##       6) X8&gt;=0.076 870  180 0 (0.97931034 0.02068966) *
##       7) X8&lt; 0.076 2732 2474 1 (0.90556369 0.09443631)  
##        14) X11_2&gt;=0.5 2270 1730 0 (0.92378855 0.07621145)  
##          28) X17_6&gt;=0.5 1350  750 0 (0.94444444 0.05555556)  
##            56) X7&gt;=-0.266 698  240 0 (0.96561605 0.03438395) *
##            57) X7&lt; -0.266 652  510 0 (0.92177914 0.07822086)  
##             114) X21_3&lt; 0.5 211   90 0 (0.95734597 0.04265403) *
##             115) X21_3&gt;=0.5 441  399 1 (0.90476190 0.09523810)  
##               230) X3&gt;=-0.7475 276  180 0 (0.93478261 0.06521739) *
##               231) X3&lt; -0.7475 165  141 1 (0.85454545 0.14545455) *
##          29) X17_6&lt; 0.5 920  822 1 (0.89347826 0.10652174)  
##            58) X21_3&lt; 0.5 389  240 0 (0.93830334 0.06169666)  
##             116) X17_3&gt;=0.5 148   20 0 (0.98648649 0.01351351) *
##             117) X17_3&lt; 0.5 241  219 1 (0.90871369 0.09128631)  
##               234) X3&gt;=-0.7475 179   90 0 (0.94972067 0.05027933) *
##               235) X3&lt; -0.7475 62   49 1 (0.79032258 0.20967742) *
##            59) X21_3&gt;=0.5 531  457 1 (0.86064030 0.13935970)  
##             118) X3&gt;=0.134 162  110 0 (0.93209877 0.06790123) *
##             119) X3&lt; 0.134 369  306 1 (0.82926829 0.17073171) *
##        15) X11_2&lt; 0.5 462  377 1 (0.81601732 0.18398268) *
</code></pre>

<pre><code class="r">plot(credit.rpart)
text(credit.rpart, pretty = TRUE)
</code></pre>

<p><img src="data:image/png;base64,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" alt="plot of chunk unnamed-chunk-12"/> </p>

<h4>Prediction using classification tree</h4>

<p>For a binary classification problem, as you learned in logistic regression there are 2 types of predictions. One is the predicted class of response (0 or 1), and the second type is the probability of response being 1. We use an additional argument type=&ldquo;class&rdquo; or type=&ldquo;prob&rdquo; to get these:</p>

<p>In-sample prediction (skipped)</p>

<p>Out-of-sample prediction</p>

<pre><code class="r"># Predicted Class
credit.test.pred.tree1 = predict(credit.rpart, credit.test, type = &quot;class&quot;)
table(credit.test$Y, credit.test.pred.tree1, dnn = c(&quot;Truth&quot;, &quot;Predicted&quot;))
</code></pre>

<pre><code>##      Predicted
## Truth   0   1
##     0 376 100
##     1   8  16
</code></pre>

<p>Usually if you want a hassle-free model, using type=&ldquo;class&rdquo; is enough <strong>given that you specified the loss matrix correctly in rpart</strong>.</p>

<p>We can get the expected loss for this tree model by defining a cost function that has the correct weights:</p>

<pre><code class="r">
cost &lt;- function(r, pi) {
    weight1 = 10
    weight0 = 1
    c1 = (r == 1) &amp; (pi == 0)  #logical vector - true if actual 1 but predict 0
    c0 = (r == 0) &amp; (pi == 1)  #logical vecotr - true if actual 0 but predict 1
    return(mean(weight1 * c1 + weight0 * c0))
}
cost(credit.test$Y, credit.test.pred.tree1)
</code></pre>

<pre><code>## [1] 0.36
</code></pre>

<p>We can compare this model&#39;s out-of-sample performance with the logistic regression model with all variables in it. Recall that when we search for the optimal cut-off using the same cost function we get optimal cut-off at about 0.08.</p>

<pre><code class="r"># Fit logistic regression model
credit.glm = glm(Y ~ . - id, data = credit.train, family = binomial)
# Get binary prediction
credit.test.pred.glm = as.numeric(predict(credit.glm, credit.test, type = &quot;response&quot;) &gt; 
    0.08)
# Calculate cost using test set
cost(credit.test$Y, credit.test.pred.glm)
</code></pre>

<pre><code>## [1] 0.378
</code></pre>

<pre><code class="r"># Confusion matrix
table(credit.test$Y, credit.test.pred.glm, dnn = c(&quot;Truth&quot;, &quot;Predicted&quot;))
</code></pre>

<pre><code>##      Predicted
## Truth   0   1
##     0 367 109
##     1   8  16
</code></pre>

<p>Which model do you think is better?</p>

<h2>ROC Curve and Cut-off Probability for Classification Tree</h2>

<p>Recall that ROC Curve gives you the trade-off between hit rate (1 - false positive) and false negative, and area under the curve (AUC) can be used as a measure of how good the binary classification model performs when you do not know the cost function.</p>

<p>To get ROC curve, we first fit a tree without the loss matrix, then get the predicted probability of Y being 1. The additional cp parameter controls the complexity of tree. Here we change it from its default 0.01 to a smaller value to grow a more complex tree than just the root node (if you use the default the tree you get will tell you to clasify everything as 0). More discussion on this in the next section. </p>

<pre><code class="r">credit.rpart2 &lt;- rpart(formula = Y ~ . - id, data = credit.train, method = &quot;class&quot;, 
    parms = list(loss = matrix(c(0, 10, 1, 0), nrow = 2)))
# Probability of getting 1
credit.test.prob.rpart2 = predict(credit.rpart2, credit.test, type = &quot;prob&quot;)
</code></pre>

<p>credit.test.prob.rpart2 has 2 columns, the first one is prob(Y) = 0 and the second prob(Y) = 1. We only need the second column because they add to 1 for binary classification.</p>

<p>To get ROC curve we use </p>

<pre><code class="r">install.packages(&quot;ROCR&quot;)
</code></pre>

<pre><code class="r">library(ROCR)
</code></pre>

<pre><code class="r">pred = prediction(credit.test.prob.rpart2[, 2], credit.test$Y)
perf = performance(pred, &quot;tpr&quot;, &quot;fpr&quot;)
plot(perf, colorize = TRUE)
</code></pre>

<p><img src="data:image/png;base64,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" alt="plot of chunk unnamed-chunk-19"/> </p>

<p>Area under the curve is given by (do not worry about the syntax here):</p>

<pre><code class="r">slot(performance(pred, &quot;auc&quot;), &quot;y.values&quot;)[[1]]
</code></pre>

<pre><code>## [1] 0.8105742
</code></pre>

<p>For a given cut-off probability, the 0/1 prediction result can be calculated similar to what you do in logistic regression</p>

<pre><code class="r">credit.test.pred.rpart2 = as.numeric(credit.test.prob.rpart2[, 2] &gt; 0.1)
table(credit.test$Y, credit.test.pred.rpart2, dnn = c(&quot;Truth&quot;, &quot;Predicted&quot;))
</code></pre>

<pre><code>##      Predicted
## Truth   0   1
##     0 376 100
##     1   8  16
</code></pre>

<p>If you know the cost structure of mis-classification, there is usually no need to search for an optimal cut-off probability as we did in the logistic regression. You can refer to the last section on specifying a loss matrix, rpart will automatically generate decision rules with your cost structure taken into consideration.</p>

<h4>Cumulative Gains Chart</h4>

<p>Cumulative Gains Chart is useful for certain types of binary classification problem. For example a direct marketing campaign, a cumulative gain chart answers the following question according to your model: what is the percentage of customers you need to contact in order to get the certain percentages of customers who will buy the product?</p>

<p>Using the Portuguese banking direct marketing dataset as example:</p>

<pre><code class="r">bank.train = read.csv(&quot;http://homepages.uc.edu/~maifg/7040/bank_train.csv&quot;)
bank.test = read.csv(&quot;http://homepages.uc.edu/~maifg/7040/bank_test.csv&quot;)
bank.pred.prob = predict(rpart(y ~ ., bank.train), bank.test)
plot(performance(prediction(bank.pred.prob, bank.test$y), &quot;tpr&quot;, &quot;rpp&quot;))
</code></pre>

<p><img src="data:image/png;base64,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" alt="plot of chunk unnamed-chunk-22"/> </p>

<p>The above graph tells you that using the predictive model, we only need to call about 40% of the customers (the 40% customers with the highest predicted probability) to get the 80% of the subscription.</p>

<h2>Pruning</h2>

<p>In rpart(), the cp(complexity parameter) argument is one of the parameters that are used to control the compexity of the tree. The help document for rpart tells you &ldquo;Any split that does not decrease the overall lack of fit by a factor of cp is not attempted&rdquo;. For a regression tree, the overall Rsquare must increase by cp at each step. Basically, the smaller the cp value, the larger (complex) tree rpart will attempt to fit.  The default value for cp is 0.01.</p>

<p>What happens when you have a large tree? The following tree has 27 splits.  </p>

<pre><code class="r">boston.largetree &lt;- rpart(formula = medv ~ ., data = boston.train, cp = 0.001)
</code></pre>

<p>Try plot it yourself to see its structure.</p>

<pre><code class="r">plot(boston.largetree)
</code></pre>

<p>The plotcp() function gives the relationship between 10-fold cross-validation error in the training set and size of tree.</p>

<pre><code class="r">plotcp(boston.largetree)
</code></pre>

<p><img src="data:image/png;base64,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" alt="plot of chunk unnamed-chunk-25"/> </p>

<p>You can observe from the above graph that the cross-validation error (x-val) does not always go down when the tree becomes more complex. The analogy is when you add more variables in a regression model, its ability to predict future observations not necessarily increases. In the Boston housing example, you may conclude that having a tree mode with more than 7-9 splits is not helptul.</p>

<p>To look at the error vs size of tree more carefully, you can look at the following table:</p>

<pre><code class="r">printcp(boston.largetree)
</code></pre>

<pre><code>## 
## Regression tree:
## rpart(formula = medv ~ ., data = boston.train, cp = 0.001)
## 
## Variables actually used in tree construction:
## [1] age     black   crim    dis     lstat   nox     ptratio rm     
## 
## Root node error: 39646/455 = 87.133
## 
## n= 455 
## 
##           CP nsplit rel error  xerror     xstd
## 1  0.4539587      0   1.00000 1.00292 0.086075
## 2  0.1820390      1   0.54604 0.66039 0.063500
## 3  0.0631306      2   0.36400 0.44240 0.052683
## 4  0.0412226      3   0.30087 0.34791 0.045697
## 5  0.0256543      4   0.25965 0.33668 0.047413
## 6  0.0184242      5   0.23399 0.31547 0.047328
## 7  0.0149444      6   0.21557 0.29871 0.046523
## 8  0.0093167      7   0.20063 0.28916 0.045873
## 9  0.0084961      8   0.19131 0.28709 0.045621
## 10 0.0077094      9   0.18281 0.28597 0.045631
## 11 0.0059561     10   0.17510 0.28415 0.044796
## 12 0.0058029     11   0.16915 0.28380 0.043306
## 13 0.0053250     12   0.16335 0.28001 0.042450
## 14 0.0047307     13   0.15802 0.27829 0.042463
## 15 0.0038404     14   0.15329 0.27265 0.042522
## 16 0.0036881     15   0.14945 0.26819 0.042468
## 17 0.0018204     16   0.14576 0.25746 0.041722
## 18 0.0016824     17   0.14394 0.25869 0.040543
## 19 0.0015845     18   0.14226 0.25761 0.040539
## 20 0.0014488     19   0.14067 0.25978 0.040593
## 21 0.0013930     20   0.13922 0.25908 0.040601
## 22 0.0013722     21   0.13783 0.25657 0.040099
## 23 0.0012861     22   0.13646 0.25729 0.040126
## 24 0.0011904     23   0.13517 0.25800 0.040067
## 25 0.0010880     24   0.13398 0.25954 0.040089
## 26 0.0010232     25   0.13290 0.25968 0.040082
## 27 0.0010000     27   0.13085 0.25965 0.040082
</code></pre>

<p>Root node error is the error when you do not do anything too smart in prediction, in regression case, it is the mean squared error(MSE) if you use the average of medv as the prediction. Note it is the same as</p>

<pre><code class="r">sum((boston.train$medv - mean(boston.train$medv))^2)/455
</code></pre>

<pre><code>## [1] 87.1332
</code></pre>

<p>The first 2 columns CP and nsplit tells you how large the tree is. rel.error \( \times \) root node error gives you the in sample error. For example, The last row 0.13085*87.133 = 11.40135, which is the same as the in-sample MSE if you calculate using predict:</p>

<pre><code class="r">mean((predict(boston.largetree) - boston.train$medv)^2)
</code></pre>

<pre><code>## [1] 11.40127
</code></pre>

<p>xerror gives you the cross-validation (default is 10-fold) error. You can see that the rel error (in-sample error) is always decreasing as model is more complex, while the cross-validation error (measure of performance on future observations) is not. That is why we <strong>prune</strong> the tree to avoid overfitting the training data.</p>

<p>The way rpart() does it is that it uses some default control parameters to avoid fitting a large tree. The main reason for this approach is to save computation time. For example by default rpart set a cp = 0.1 and the minimum number of observations that must exist in a node to be 20. Use ?rpart.control to view these parameters. Sometimes we wish to change these paramters to see how more complex trees will perform, as we did above. If we have a larger than necessary tree, we can use prune() function and specify a new cp:</p>

<pre><code class="r">prune(boston.largetree, cp = 0.05)
</code></pre>

<pre><code>## n= 455 
## 
## node), split, n, deviance, yval
##       * denotes terminal node
## 
## 1) root 455 39645.610 22.60835  
##   2) rm&lt; 6.9715 390 16846.500 20.04077  
##     4) lstat&gt;=14.4 160  3066.144 14.88313 *
##     5) lstat&lt; 14.4 230  6563.311 23.62870 *
##   3) rm&gt;=6.9715 65  4801.638 38.01385  
##     6) rm&lt; 7.437 36  1224.809 32.44444 *
##     7) rm&gt;=7.437 29  1073.978 44.92759 *
</code></pre>

<p>Some software/packages can automatically prune the tree.</p>

</body>

</html>

