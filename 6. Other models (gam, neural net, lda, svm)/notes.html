<!DOCTYPE html>
<!-- saved from url=(0014)about:internet -->
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
<meta http-equiv="x-ua-compatible" content="IE=9" >

<title>Other Supervised Learning Methods</title>

<style type="text/css">
body, td {
   font-family: sans-serif;
   background-color: white;
   font-size: 12px;
   margin: 8px;
}

tt, code, pre {
   font-family: 'DejaVu Sans Mono', 'Droid Sans Mono', 'Lucida Console', Consolas, Monaco, monospace;
}

h1 { 
   font-size:2.2em; 
}

h2 { 
   font-size:1.8em; 
}

h3 { 
   font-size:1.4em; 
}

h4 { 
   font-size:1.0em; 
}

h5 { 
   font-size:0.9em; 
}

h6 { 
   font-size:0.8em; 
}

a:visited {
   color: rgb(50%, 0%, 50%);
}

pre {	
   margin-top: 0;
   max-width: 95%;
   border: 1px solid #ccc;
   white-space: pre-wrap;
}

pre code {
   display: block; padding: 0.5em;
}

code.r, code.cpp {
   background-color: #F8F8F8;
}

table, td, th {
  border: none;
}

blockquote {
   color:#666666;
   margin:0;
   padding-left: 1em;
   border-left: 0.5em #EEE solid;
}

hr {
   height: 0px;
   border-bottom: none;
   border-top-width: thin;
   border-top-style: dotted;
   border-top-color: #999999;
}

@media print {
   * { 
      background: transparent !important; 
      color: black !important; 
      filter:none !important; 
      -ms-filter: none !important; 
   }

   body { 
      font-size:12pt; 
      max-width:100%; 
   }
       
   a, a:visited { 
      text-decoration: underline; 
   }

   hr { 
      visibility: hidden;
      page-break-before: always;
   }

   pre, blockquote { 
      padding-right: 1em; 
      page-break-inside: avoid; 
   }

   tr, img { 
      page-break-inside: avoid; 
   }

   img { 
      max-width: 100% !important; 
   }

   @page :left { 
      margin: 15mm 20mm 15mm 10mm; 
   }
     
   @page :right { 
      margin: 15mm 10mm 15mm 20mm; 
   }

   p, h2, h3 { 
      orphans: 3; widows: 3; 
   }

   h2, h3 { 
      page-break-after: avoid; 
   }
}

</style>

<!-- Styles for R syntax highlighter -->
<style type="text/css">
   pre .operator,
   pre .paren {
     color: rgb(104, 118, 135)
   }

   pre .literal {
     color: rgb(88, 72, 246)
   }

   pre .number {
     color: rgb(0, 0, 205);
   }

   pre .comment {
     color: rgb(76, 136, 107);
   }

   pre .keyword {
     color: rgb(0, 0, 255);
   }

   pre .identifier {
     color: rgb(0, 0, 0);
   }

   pre .string {
     color: rgb(3, 106, 7);
   }
</style>

<!-- R syntax highlighter -->
<script type="text/javascript">
var hljs=new function(){function m(p){return p.replace(/&/gm,"&amp;").replace(/</gm,"&lt;")}function f(r,q,p){return RegExp(q,"m"+(r.cI?"i":"")+(p?"g":""))}function b(r){for(var p=0;p<r.childNodes.length;p++){var q=r.childNodes[p];if(q.nodeName=="CODE"){return q}if(!(q.nodeType==3&&q.nodeValue.match(/\s+/))){break}}}function h(t,s){var p="";for(var r=0;r<t.childNodes.length;r++){if(t.childNodes[r].nodeType==3){var q=t.childNodes[r].nodeValue;if(s){q=q.replace(/\n/g,"")}p+=q}else{if(t.childNodes[r].nodeName=="BR"){p+="\n"}else{p+=h(t.childNodes[r])}}}if(/MSIE [678]/.test(navigator.userAgent)){p=p.replace(/\r/g,"\n")}return p}function a(s){var r=s.className.split(/\s+/);r=r.concat(s.parentNode.className.split(/\s+/));for(var q=0;q<r.length;q++){var p=r[q].replace(/^language-/,"");if(e[p]){return p}}}function c(q){var p=[];(function(s,t){for(var r=0;r<s.childNodes.length;r++){if(s.childNodes[r].nodeType==3){t+=s.childNodes[r].nodeValue.length}else{if(s.childNodes[r].nodeName=="BR"){t+=1}else{if(s.childNodes[r].nodeType==1){p.push({event:"start",offset:t,node:s.childNodes[r]});t=arguments.callee(s.childNodes[r],t);p.push({event:"stop",offset:t,node:s.childNodes[r]})}}}}return t})(q,0);return p}function k(y,w,x){var q=0;var z="";var s=[];function u(){if(y.length&&w.length){if(y[0].offset!=w[0].offset){return(y[0].offset<w[0].offset)?y:w}else{return w[0].event=="start"?y:w}}else{return y.length?y:w}}function t(D){var A="<"+D.nodeName.toLowerCase();for(var B=0;B<D.attributes.length;B++){var C=D.attributes[B];A+=" "+C.nodeName.toLowerCase();if(C.value!==undefined&&C.value!==false&&C.value!==null){A+='="'+m(C.value)+'"'}}return A+">"}while(y.length||w.length){var v=u().splice(0,1)[0];z+=m(x.substr(q,v.offset-q));q=v.offset;if(v.event=="start"){z+=t(v.node);s.push(v.node)}else{if(v.event=="stop"){var p,r=s.length;do{r--;p=s[r];z+=("</"+p.nodeName.toLowerCase()+">")}while(p!=v.node);s.splice(r,1);while(r<s.length){z+=t(s[r]);r++}}}}return z+m(x.substr(q))}function j(){function q(x,y,v){if(x.compiled){return}var u;var s=[];if(x.k){x.lR=f(y,x.l||hljs.IR,true);for(var w in x.k){if(!x.k.hasOwnProperty(w)){continue}if(x.k[w] instanceof Object){u=x.k[w]}else{u=x.k;w="keyword"}for(var r in u){if(!u.hasOwnProperty(r)){continue}x.k[r]=[w,u[r]];s.push(r)}}}if(!v){if(x.bWK){x.b="\\b("+s.join("|")+")\\s"}x.bR=f(y,x.b?x.b:"\\B|\\b");if(!x.e&&!x.eW){x.e="\\B|\\b"}if(x.e){x.eR=f(y,x.e)}}if(x.i){x.iR=f(y,x.i)}if(x.r===undefined){x.r=1}if(!x.c){x.c=[]}x.compiled=true;for(var t=0;t<x.c.length;t++){if(x.c[t]=="self"){x.c[t]=x}q(x.c[t],y,false)}if(x.starts){q(x.starts,y,false)}}for(var p in e){if(!e.hasOwnProperty(p)){continue}q(e[p].dM,e[p],true)}}function d(B,C){if(!j.called){j();j.called=true}function q(r,M){for(var L=0;L<M.c.length;L++){if((M.c[L].bR.exec(r)||[null])[0]==r){return M.c[L]}}}function v(L,r){if(D[L].e&&D[L].eR.test(r)){return 1}if(D[L].eW){var M=v(L-1,r);return M?M+1:0}return 0}function w(r,L){return L.i&&L.iR.test(r)}function K(N,O){var M=[];for(var L=0;L<N.c.length;L++){M.push(N.c[L].b)}var r=D.length-1;do{if(D[r].e){M.push(D[r].e)}r--}while(D[r+1].eW);if(N.i){M.push(N.i)}return f(O,M.join("|"),true)}function p(M,L){var N=D[D.length-1];if(!N.t){N.t=K(N,E)}N.t.lastIndex=L;var r=N.t.exec(M);return r?[M.substr(L,r.index-L),r[0],false]:[M.substr(L),"",true]}function z(N,r){var L=E.cI?r[0].toLowerCase():r[0];var M=N.k[L];if(M&&M instanceof Array){return M}return false}function F(L,P){L=m(L);if(!P.k){return L}var r="";var O=0;P.lR.lastIndex=0;var M=P.lR.exec(L);while(M){r+=L.substr(O,M.index-O);var N=z(P,M);if(N){x+=N[1];r+='<span class="'+N[0]+'">'+M[0]+"</span>"}else{r+=M[0]}O=P.lR.lastIndex;M=P.lR.exec(L)}return r+L.substr(O,L.length-O)}function J(L,M){if(M.sL&&e[M.sL]){var r=d(M.sL,L);x+=r.keyword_count;return r.value}else{return F(L,M)}}function I(M,r){var L=M.cN?'<span class="'+M.cN+'">':"";if(M.rB){y+=L;M.buffer=""}else{if(M.eB){y+=m(r)+L;M.buffer=""}else{y+=L;M.buffer=r}}D.push(M);A+=M.r}function G(N,M,Q){var R=D[D.length-1];if(Q){y+=J(R.buffer+N,R);return false}var P=q(M,R);if(P){y+=J(R.buffer+N,R);I(P,M);return P.rB}var L=v(D.length-1,M);if(L){var O=R.cN?"</span>":"";if(R.rE){y+=J(R.buffer+N,R)+O}else{if(R.eE){y+=J(R.buffer+N,R)+O+m(M)}else{y+=J(R.buffer+N+M,R)+O}}while(L>1){O=D[D.length-2].cN?"</span>":"";y+=O;L--;D.length--}var r=D[D.length-1];D.length--;D[D.length-1].buffer="";if(r.starts){I(r.starts,"")}return R.rE}if(w(M,R)){throw"Illegal"}}var E=e[B];var D=[E.dM];var A=0;var x=0;var y="";try{var s,u=0;E.dM.buffer="";do{s=p(C,u);var t=G(s[0],s[1],s[2]);u+=s[0].length;if(!t){u+=s[1].length}}while(!s[2]);if(D.length>1){throw"Illegal"}return{r:A,keyword_count:x,value:y}}catch(H){if(H=="Illegal"){return{r:0,keyword_count:0,value:m(C)}}else{throw H}}}function g(t){var p={keyword_count:0,r:0,value:m(t)};var r=p;for(var q in e){if(!e.hasOwnProperty(q)){continue}var s=d(q,t);s.language=q;if(s.keyword_count+s.r>r.keyword_count+r.r){r=s}if(s.keyword_count+s.r>p.keyword_count+p.r){r=p;p=s}}if(r.language){p.second_best=r}return p}function i(r,q,p){if(q){r=r.replace(/^((<[^>]+>|\t)+)/gm,function(t,w,v,u){return w.replace(/\t/g,q)})}if(p){r=r.replace(/\n/g,"<br>")}return r}function n(t,w,r){var x=h(t,r);var v=a(t);var y,s;if(v){y=d(v,x)}else{return}var q=c(t);if(q.length){s=document.createElement("pre");s.innerHTML=y.value;y.value=k(q,c(s),x)}y.value=i(y.value,w,r);var u=t.className;if(!u.match("(\\s|^)(language-)?"+v+"(\\s|$)")){u=u?(u+" "+v):v}if(/MSIE [678]/.test(navigator.userAgent)&&t.tagName=="CODE"&&t.parentNode.tagName=="PRE"){s=t.parentNode;var p=document.createElement("div");p.innerHTML="<pre><code>"+y.value+"</code></pre>";t=p.firstChild.firstChild;p.firstChild.cN=s.cN;s.parentNode.replaceChild(p.firstChild,s)}else{t.innerHTML=y.value}t.className=u;t.result={language:v,kw:y.keyword_count,re:y.r};if(y.second_best){t.second_best={language:y.second_best.language,kw:y.second_best.keyword_count,re:y.second_best.r}}}function o(){if(o.called){return}o.called=true;var r=document.getElementsByTagName("pre");for(var p=0;p<r.length;p++){var q=b(r[p]);if(q){n(q,hljs.tabReplace)}}}function l(){if(window.addEventListener){window.addEventListener("DOMContentLoaded",o,false);window.addEventListener("load",o,false)}else{if(window.attachEvent){window.attachEvent("onload",o)}else{window.onload=o}}}var e={};this.LANGUAGES=e;this.highlight=d;this.highlightAuto=g;this.fixMarkup=i;this.highlightBlock=n;this.initHighlighting=o;this.initHighlightingOnLoad=l;this.IR="[a-zA-Z][a-zA-Z0-9_]*";this.UIR="[a-zA-Z_][a-zA-Z0-9_]*";this.NR="\\b\\d+(\\.\\d+)?";this.CNR="\\b(0[xX][a-fA-F0-9]+|(\\d+(\\.\\d*)?|\\.\\d+)([eE][-+]?\\d+)?)";this.BNR="\\b(0b[01]+)";this.RSR="!|!=|!==|%|%=|&|&&|&=|\\*|\\*=|\\+|\\+=|,|\\.|-|-=|/|/=|:|;|<|<<|<<=|<=|=|==|===|>|>=|>>|>>=|>>>|>>>=|\\?|\\[|\\{|\\(|\\^|\\^=|\\||\\|=|\\|\\||~";this.ER="(?![\\s\\S])";this.BE={b:"\\\\.",r:0};this.ASM={cN:"string",b:"'",e:"'",i:"\\n",c:[this.BE],r:0};this.QSM={cN:"string",b:'"',e:'"',i:"\\n",c:[this.BE],r:0};this.CLCM={cN:"comment",b:"//",e:"$"};this.CBLCLM={cN:"comment",b:"/\\*",e:"\\*/"};this.HCM={cN:"comment",b:"#",e:"$"};this.NM={cN:"number",b:this.NR,r:0};this.CNM={cN:"number",b:this.CNR,r:0};this.BNM={cN:"number",b:this.BNR,r:0};this.inherit=function(r,s){var p={};for(var q in r){p[q]=r[q]}if(s){for(var q in s){p[q]=s[q]}}return p}}();hljs.LANGUAGES.cpp=function(){var a={keyword:{"false":1,"int":1,"float":1,"while":1,"private":1,"char":1,"catch":1,"export":1,virtual:1,operator:2,sizeof:2,dynamic_cast:2,typedef:2,const_cast:2,"const":1,struct:1,"for":1,static_cast:2,union:1,namespace:1,unsigned:1,"long":1,"throw":1,"volatile":2,"static":1,"protected":1,bool:1,template:1,mutable:1,"if":1,"public":1,friend:2,"do":1,"return":1,"goto":1,auto:1,"void":2,"enum":1,"else":1,"break":1,"new":1,extern:1,using:1,"true":1,"class":1,asm:1,"case":1,typeid:1,"short":1,reinterpret_cast:2,"default":1,"double":1,register:1,explicit:1,signed:1,typename:1,"try":1,"this":1,"switch":1,"continue":1,wchar_t:1,inline:1,"delete":1,alignof:1,char16_t:1,char32_t:1,constexpr:1,decltype:1,noexcept:1,nullptr:1,static_assert:1,thread_local:1,restrict:1,_Bool:1,complex:1},built_in:{std:1,string:1,cin:1,cout:1,cerr:1,clog:1,stringstream:1,istringstream:1,ostringstream:1,auto_ptr:1,deque:1,list:1,queue:1,stack:1,vector:1,map:1,set:1,bitset:1,multiset:1,multimap:1,unordered_set:1,unordered_map:1,unordered_multiset:1,unordered_multimap:1,array:1,shared_ptr:1}};return{dM:{k:a,i:"</",c:[hljs.CLCM,hljs.CBLCLM,hljs.QSM,{cN:"string",b:"'\\\\?.",e:"'",i:"."},{cN:"number",b:"\\b(\\d+(\\.\\d*)?|\\.\\d+)(u|U|l|L|ul|UL|f|F)"},hljs.CNM,{cN:"preprocessor",b:"#",e:"$"},{cN:"stl_container",b:"\\b(deque|list|queue|stack|vector|map|set|bitset|multiset|multimap|unordered_map|unordered_set|unordered_multiset|unordered_multimap|array)\\s*<",e:">",k:a,r:10,c:["self"]}]}}}();hljs.LANGUAGES.r={dM:{c:[hljs.HCM,{cN:"number",b:"\\b0[xX][0-9a-fA-F]+[Li]?\\b",e:hljs.IMMEDIATE_RE,r:0},{cN:"number",b:"\\b\\d+(?:[eE][+\\-]?\\d*)?L\\b",e:hljs.IMMEDIATE_RE,r:0},{cN:"number",b:"\\b\\d+\\.(?!\\d)(?:i\\b)?",e:hljs.IMMEDIATE_RE,r:1},{cN:"number",b:"\\b\\d+(?:\\.\\d*)?(?:[eE][+\\-]?\\d*)?i?\\b",e:hljs.IMMEDIATE_RE,r:0},{cN:"number",b:"\\.\\d+(?:[eE][+\\-]?\\d*)?i?\\b",e:hljs.IMMEDIATE_RE,r:1},{cN:"keyword",b:"(?:tryCatch|library|setGeneric|setGroupGeneric)\\b",e:hljs.IMMEDIATE_RE,r:10},{cN:"keyword",b:"\\.\\.\\.",e:hljs.IMMEDIATE_RE,r:10},{cN:"keyword",b:"\\.\\.\\d+(?![\\w.])",e:hljs.IMMEDIATE_RE,r:10},{cN:"keyword",b:"\\b(?:function)",e:hljs.IMMEDIATE_RE,r:2},{cN:"keyword",b:"(?:if|in|break|next|repeat|else|for|return|switch|while|try|stop|warning|require|attach|detach|source|setMethod|setClass)\\b",e:hljs.IMMEDIATE_RE,r:1},{cN:"literal",b:"(?:NA|NA_integer_|NA_real_|NA_character_|NA_complex_)\\b",e:hljs.IMMEDIATE_RE,r:10},{cN:"literal",b:"(?:NULL|TRUE|FALSE|T|F|Inf|NaN)\\b",e:hljs.IMMEDIATE_RE,r:1},{cN:"identifier",b:"[a-zA-Z.][a-zA-Z0-9._]*\\b",e:hljs.IMMEDIATE_RE,r:0},{cN:"operator",b:"<\\-(?!\\s*\\d)",e:hljs.IMMEDIATE_RE,r:2},{cN:"operator",b:"\\->|<\\-",e:hljs.IMMEDIATE_RE,r:1},{cN:"operator",b:"%%|~",e:hljs.IMMEDIATE_RE},{cN:"operator",b:">=|<=|==|!=|\\|\\||&&|=|\\+|\\-|\\*|/|\\^|>|<|!|&|\\||\\$|:",e:hljs.IMMEDIATE_RE,r:0},{cN:"operator",b:"%",e:"%",i:"\\n",r:1},{cN:"identifier",b:"`",e:"`",r:0},{cN:"string",b:'"',e:'"',c:[hljs.BE],r:0},{cN:"string",b:"'",e:"'",c:[hljs.BE],r:0},{cN:"paren",b:"[[({\\])}]",e:hljs.IMMEDIATE_RE,r:0}]}};
hljs.initHighlightingOnLoad();
</script>




</head>

<body>
<h1>Other Supervised Learning Methods</h1>

<p>This tutorial helps you to review various supervised learning techniques, introduce GAM, Neural Networks models, and prepare you to finish Case Study 1.</p>

<hr/>

<h2><a id="content"></a> Content </h2>

<h3><a href="#data">Credit Score Data</a></h3>

<h3><a href="#glm">Generalized Linear Models</a></h3>

<h3><a href="#tree">Tree Models (omitted)</a></h3>

<h3><a href="#gam">Generalized Additive Models (GAM)</a></h3>

<h3><a href="#da">Discriminant Analysis</a></h3>

<h3><a href="#nnet">Neural Networks Models</a></h3>

<h3><a href="#svm">SVM</a></h3>

<h3><a href="#compare">Performance Comparisons</a></h3>

<h3><a href="#german">Starter Code for German Credit Score</a></h3>

<hr/>

<h3><a id="data"></a>Credit Score Data <a id="data"></a></h3>

<h4>Load Data</h4>

<pre><code class="r">credit.data &lt;- read.csv(&quot;http://homepages.uc.edu/~maifg/7040/credit0.csv&quot;, header = T)
</code></pre>

<p>We remove X9 and id from the data since we will not be using them for prediction.</p>

<pre><code class="r">credit.data$X9 = NULL
credit.data$id = NULL
</code></pre>

<p>Now split the data 90/10 as training/testing datasets:</p>

<pre><code class="r">set.seed(2014)
subset &lt;- sample(nrow(credit.data), nrow(credit.data) * 0.9)
credit.train = credit.data[subset, ]
credit.test = credit.data[-subset, ]
</code></pre>

<p>The training dataset has 61 variables, 4500 obs. </p>

<p>You are already familiar with the credit scoring set. Let&#39;s define a cost function for benchmarking testing set performance. Note this is slightly different from the one we used for searching for optimal cut-off probability in logistic regression. Here the 2nd argument is the predict class instead of the predict probability (since many methods are not based on predict probability).</p>

<pre><code class="r">creditcost &lt;- function(observed, predicted) {
    weight1 = 10
    weight0 = 1
    c1 = (observed == 1) &amp; (predicted == 0)  #logical vector - true if actual 1 but predict 0
    c0 = (observed == 0) &amp; (predicted == 1)  #logical vecotr - true if actual 0 but predict 1
    return(mean(weight1 * c1 + weight0 * c0))
}
</code></pre>

<h3><a id="glm"></a> Generalized Linear Models (Logistic Regression)</h3>

<p>Let&#39;s build a logistic regression model based on all X variables. Note id is excluded from the model.</p>

<pre><code class="r">credit.glm0 &lt;- glm(Y ~ ., family = binomial, credit.train)
</code></pre>

<p>You can view the result of the estimation:</p>

<pre><code class="r">summary(credit.glm0)
</code></pre>

<p>The usual stepwise variable selection still works for logistic regression. <strong>caution: this will take a very long time</strong>.</p>

<pre><code class="r">credit.glm.step &lt;- step(credit.glm0, direction = c(&quot;both&quot;))
</code></pre>

<p>Or you can try model selection with BIC:</p>

<pre><code class="r">credit.glm.step &lt;- step(credit.glm0, k = log(nrow(credit.train)), direction = c(&quot;both&quot;))
</code></pre>

<p>Are there better ways of doing variable selection for genearlized linear models? Yes! (And you should probably know about it.) Check the optional lab notes on <em>Lasso variable selection</em> and Section 3.4 of the textbook &ldquo;Elements of Statistical Learning&rdquo;.</p>

<p>If you want a sneak peek on how to use Lasso for this dataset here it is:</p>

<pre><code class="r">install.packages(&quot;glmnet&quot;)
</code></pre>

<pre><code class="r">library(glmnet)
</code></pre>

<pre><code>## Loading required package: Matrix
## Loading required package: lattice
## Loaded glmnet 1.9-5
</code></pre>

<pre><code class="r">lasso_fit = glmnet(x = as.matrix(credit.train[, 2:61]), y = credit.train[, 1], 
    family = &quot;binomial&quot;, alpha = 1)
coef(lasso_fit, s = 0.02)
</code></pre>

<pre><code>## 61 x 1 sparse Matrix of class &quot;dgCMatrix&quot;
##                    1
## (Intercept) -2.33668
## X2           .      
## X3           .      
## X4           .      
## X5           .      
## X6           .      
## X7           .      
## X8          -0.30245
## X10_2        .      
## X11_2       -0.44366
## X12_2        .      
## X13_2        .      
## X14_2        .      
## X15_2        .      
## X15_3        .      
## X15_4        .      
## X15_5        .      
## X15_6        .      
## X16_2        .      
## X16_3        .      
## X16_4        .      
## X16_5        .      
## X16_6        .      
## X17_2        .      
## X17_3        .      
## X17_4        .      
## X17_5        .      
## X17_6       -0.12724
## X18_2        .      
## X18_3        .      
## X18_4        .      
## X18_5        .      
## X18_6        .      
## X18_7        .      
## X19_2        .      
## X19_3        .      
## X19_4        .      
## X19_5        .      
## X19_6        .      
## X19_7        .      
## X19_8        .      
## X19_9        .      
## X19_10       .      
## X20_2        .      
## X20_3        .      
## X20_4        .      
## X21_2        .      
## X21_3        .      
## X22_2        .      
## X22_3        .      
## X22_4        .      
## X22_5        .      
## X22_6        .      
## X22_7        .      
## X22_8        .      
## X22_9        0.05367
## X22_10       .      
## X22_11       .      
## X23_2        .      
## X23_3        .      
## X24_2        .
</code></pre>

<p>The <em>s</em> parameter determines how many variables are included and you can use cross-validation to choose it.</p>

<h4>Prediction and Cross Validation Using Logistic Regression</h4>

<h5>Performance on testing set</h5>

<p>To do out-of-sample prediction you need to add the testing set as a second argument after the glm object. Remember to add type = &ldquo;response&rdquo;, otherwise you will get the log odds and not the probability.</p>

<pre><code class="r">prob.glm0.outsample &lt;- predict(credit.glm0, credit.test, type = &quot;response&quot;)
predicted.glm0.outsample &lt;- prob.glm0.outsample &gt; 0.2
predicted.glm0.outsample &lt;- as.numeric(predicted.glm0.outsample)
table(credit.test$Y, predicted.glm0.outsample, dnn = c(&quot;Truth&quot;, &quot;Predicted&quot;))
</code></pre>

<pre><code>##      Predicted
## Truth   0   1
##     0 445  29
##     1  20   6
</code></pre>

<pre><code class="r">mean(ifelse(credit.test$Y != predicted.glm0.outsample, 1, 0))
</code></pre>

<pre><code>## [1] 0.098
</code></pre>

<pre><code class="r">creditcost(credit.test$Y, predicted.glm0.outsample)
</code></pre>

<pre><code>## [1] 0.458
</code></pre>

<h4>ROC Curve</h4>

<p>To get the ROC curve you need to install the verification library.</p>

<pre><code class="r">install.packages(&quot;verification&quot;)
</code></pre>

<p>To plot the ROC curve, the first argument of roc.plot is the vector with actual values &ldquo;A binary observation (coded {0, 1 } )&rdquo;. The second argument is the vector with predicted probability. </p>

<pre><code class="r">library(&quot;verification&quot;)
</code></pre>

<pre><code class="r">roc.plot(credit.test$Y == &quot;1&quot;, prob.glm0.outsample)
</code></pre>

<p>To get the area under the ROC curve:</p>

<pre><code class="r">roc.plot(credit.test$Y == &quot;1&quot;, prob.glm0.outsample)$roc.vol
</code></pre>

<p><img src="data:image/png;base64,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" alt="plot of chunk unnamed-chunk-15"/> </p>

<pre><code>##      Model  Area   p.value binorm.area
## 1 Model  1 0.696 0.0003793          NA
</code></pre>

<p><a href="#content">go to top</a></p>

<hr/>

<h3><a id="gam"></a> Generalized Additive Models (GAM)</h3>

<p>There are two common implementations of GAMs in R.  The older version (originally made for S-PLUS) is available as the &#39;gam&#39; package by Hastie and Tibshirani.  The newer version that we will use below is the &#39;mgcv&#39; package from Simon Wood.  The basic modeling procedure for both packages is similar (the function is gam for both; be wary of having both libraries loaded at the same time), but the behind-the-scenes computational approaches differ, as do the arguments for optimization and the model output.  Expect the results to be slightly different when used with the same model structure on the same dataset.</p>

<pre><code class="r">library(mgcv)
</code></pre>

<pre><code>## Loading required package: nlme
## This is mgcv 1.7-27. For overview type &#39;help(&quot;mgcv-package&quot;)&#39;.
</code></pre>

<pre><code class="r">
## Create a formula for a model with a large number of variables:
gam_formula &lt;- as.formula(paste(&quot;Y~s(X2)+s(X3)+s(X4)+s(X5)+&quot;, paste(colnames(credit.train)[6:61], 
    collapse = &quot;+&quot;)))

credit.gam &lt;- gam(formula = gam_formula, family = binomial, data = credit.train)
summary(credit.gam)
</code></pre>

<pre><code>## 
## Family: binomial 
## Link function: logit 
## 
## Formula:
## Y ~ s(X2) + s(X3) + s(X4) + s(X5) + X6 + X7 + X8 + X10_2 + X11_2 + 
##     X12_2 + X13_2 + X14_2 + X15_2 + X15_3 + X15_4 + X15_5 + X15_6 + 
##     X16_2 + X16_3 + X16_4 + X16_5 + X16_6 + X17_2 + X17_3 + X17_4 + 
##     X17_5 + X17_6 + X18_2 + X18_3 + X18_4 + X18_5 + X18_6 + X18_7 + 
##     X19_2 + X19_3 + X19_4 + X19_5 + X19_6 + X19_7 + X19_8 + X19_9 + 
##     X19_10 + X20_2 + X20_3 + X20_4 + X21_2 + X21_3 + X22_2 + 
##     X22_3 + X22_4 + X22_5 + X22_6 + X22_7 + X22_8 + X22_9 + X22_10 + 
##     X22_11 + X23_2 + X23_3 + X24_2
## 
## Parametric coefficients:
##             Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)  -3.6765     0.7201   -5.11  3.3e-07 ***
## X6            0.2279     0.1125    2.03  0.04271 *  
## X7           -0.3074     0.2080   -1.48  0.13948    
## X8           -2.1742     0.3204   -6.79  1.2e-11 ***
## X10_2        -0.2521     0.1682   -1.50  0.13389    
## X11_2        -0.9394     0.1515   -6.20  5.6e-10 ***
## X12_2        -0.4049     0.1971   -2.05  0.04000 *  
## X13_2         0.4319     0.1581    2.73  0.00628 ** 
## X14_2        -0.2425     0.2742   -0.88  0.37644    
## X15_2         0.5583     0.2459    2.27  0.02318 *  
## X15_3         0.3442     0.3003    1.15  0.25168    
## X15_4         0.9255     0.3235    2.86  0.00422 ** 
## X15_5         0.4021     0.4231    0.95  0.34189    
## X15_6         1.1292     0.2765    4.08  4.4e-05 ***
## X16_2         0.3897     0.2876    1.35  0.17543    
## X16_3        -0.0280     0.2836   -0.10  0.92148    
## X16_4         0.2302     0.3494    0.66  0.50997    
## X16_5        -0.1222     0.2844   -0.43  0.66728    
## X16_6         0.0465     0.2992    0.16  0.87639    
## X17_2        -0.0792     0.2512   -0.32  0.75268    
## X17_3        -1.0140     0.3088   -3.28  0.00103 ** 
## X17_4        -0.3429     0.2671   -1.28  0.19925    
## X17_5         0.9316     0.4095    2.28  0.02289 *  
## X17_6        -1.1423     0.1730   -6.60  4.0e-11 ***
## X18_2         0.3094     0.3323    0.93  0.35184    
## X18_3         0.5291     0.2710    1.95  0.05089 .  
## X18_4         1.0325     0.2620    3.94  8.1e-05 ***
## X18_5         0.8386     0.2431    3.45  0.00056 ***
## X18_6         0.5729     0.2932    1.95  0.05073 .  
## X18_7         0.7245     0.3129    2.32  0.02060 *  
## X19_2         0.2809     0.3722    0.75  0.45043    
## X19_3         0.6587     0.3023    2.18  0.02934 *  
## X19_4         0.2070     0.5166    0.40  0.68860    
## X19_5         0.1995     0.4243    0.47  0.63829    
## X19_6         0.2967     0.4603    0.64  0.51925    
## X19_7         0.6131     0.4338    1.41  0.15761    
## X19_8        -0.8687     0.6777   -1.28  0.19988    
## X19_9         1.0743     0.5435    1.98  0.04808 *  
## X19_10        0.5598     0.3382    1.66  0.09790 .  
## X20_2        -0.0689     0.3568   -0.19  0.84689    
## X20_3        -0.0321     0.2652   -0.12  0.90357    
## X20_4         0.0971     0.1815    0.53  0.59278    
## X21_2         0.3554     0.4311    0.82  0.40975    
## X21_3         0.5772     0.2197    2.63  0.00860 ** 
## X22_2        -0.5262     0.4098   -1.28  0.19909    
## X22_3         0.1185     0.3407    0.35  0.72801    
## X22_4        -0.0224     0.4401   -0.05  0.95946    
## X22_5        -0.0274     0.4213   -0.06  0.94819    
## X22_6         0.0425     0.5898    0.07  0.94250    
## X22_7         0.2777     0.3632    0.76  0.44442    
## X22_8        -0.0357     0.3577   -0.10  0.92050    
## X22_9         0.5717     0.3150    1.82  0.06950 .  
## X22_10       -1.2721     1.0789   -1.18  0.23838    
## X22_11        0.4207     0.3415    1.23  0.21790    
## X23_2         0.1157     0.2064    0.56  0.57489    
## X23_3        -0.2381     0.2247   -1.06  0.28938    
## X24_2         0.3286     0.3019    1.09  0.27640    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Approximate significance of smooth terms:
##        edf Ref.df Chi.sq p-value    
## s(X2) 1.00   1.00   0.99    0.32    
## s(X3) 1.00   1.00  20.25 6.9e-06 ***
## s(X4) 1.89   2.37   2.53    0.34    
## s(X5) 2.88   3.59   6.27    0.14    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## R-sq.(adj) =  0.123   Deviance explained = 19.6%
## UBRE score = -0.60285  Scale est. = 1         n = 4500
</code></pre>

<pre><code class="r">plot(credit.gam, shade = TRUE, , seWithMean = TRUE, scale = 0)
</code></pre>

<p><img src="data:image/png;base64,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" alt="plot of chunk unnamed-chunk-16"/> <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAfgAAAH4CAMAAACR9g9NAAAAeFBMVEX9/v0AAAAAADkAAGUAOTkAOY8AZrU5AAA5ADk5AGU5OY85ZrU5j9plAABlADllAGVlOY9lZmVlZrVltf2POQCPOTmPOWWPtY+P29qP2/21ZgC1ZmW1/rW1/tq1/v3MzMzajzna/tra/v39tWX924/9/rX9/tr9/v1fpw3lAAAAKHRSTlP///////////////////////////////////////////////////8AvqouGAAAAAlwSFlzAAALEgAACxIB0t1+/AAADjlJREFUeJzt3QF327YVhuHKXZPViZttSdPG2yrPkq3//w9nyk7igJJNELi4F/je9+ycTltKQnwCkZIt4qcDSfaT9wDIJ+BFA1404EUDXjTgRQNeNOBFA1404EUDXjTgRQNeNOBFA1404EUDXjTgRQNeNOBFA1404EUDXjTgRQNeNOBFA1404EUDXjTgRQNeNOBFA1404EUDXjTgRQNeNOBFA1404EUDXjTgRQNeNOBFA1404EUDXjTgRQNeNOBFA1404EUDXjTgRQNeNOBFA1404EUrgd9Q5AzhC/5dsg540YAXDXjRgBcNeNGAFw140YAXDXjRgBcNeNGAF60d/HZbsC2qXUt45APVFB75OLWFhz5MreGRD1JzeORj1B4e+hB5wCMfIBd45P3zgUfePSd45L3zgkfeOTd46H1zhEfeM0945B1zhYfeL2d45L3yhkfeKXd46H0KAA+9RyHgoW9fEHjkWxcFHvnGhYGHvm2B4JFvWSn83Ye/DndXm80vt69t+nV45BtWAX6yP+zfvbbpBfDQt6sC/P7y9nHmv7zpRfDIt6oY/uriz8/TjL+cvdavgke+UeUXd/efNm8Ou59nE34lPPRtinRVD33DQsIjb18t+GcXd2fuj5wDj7x57Wb8BvlINXyp30AfqGL4/dvjy/qiq/o8+pynQbmVwt9/+nj8527+me2pc3wWfcbToNxqfFb//J/nN/2kCX2MGs/4I32GPPRWFZ/jpx/NLT3Hr5n00Nvk8wEO8u45fXLHmd47t49smfS++X1Wz5neNc8f0kDvmO9P55B3y/nHslzkeeX+83gmvU/u8JzpffKHh96lCPDQOxQDnqu85kWBz7vKKxgVPRYHPmvSFwyLjgWCZ9K3LBQ8Z/p2xYKHvlnR4KFvVDx46JsUEZ4L/AbFhM+6wC8YonBR4XlrZ1xYeM70tsWF50f1pkWG54d2hoWGh96u4PDQW9UOHvpQtYRfT5/1pwuGLFRb+LX03EWleq3hV9Pn/fGCYYvUHn5qjTz0VfOBb0FfMHKFvOBXveJDXy83eOh9c4SH3jNXeOj9coZfSZ/3xwuew7i5w09Zy0M/LwT8it/SyP0XCp7HmAWBz//NLOjLCgMPfdsCwUPfslDw0LcrGLzpb2FD/6x2K1QsLlM+nx78Q8v71WeUSb9CHvp2K1RklSfPpM8v5Iw/8HpvXrsVKnKD3rRwV/XPgt6wyPDQG9Zubdl1NaDXxI8946cy6VfJC9LHh2/x3k6QPuAndyfKo18nL0Yf9X18WpY89K8X9JO7EzWh18HvZcZPQV+xuJ/cnSqLfrW8BH0PV/XPayMvYN8bvNmtUdXo+4PPoi+RH5u+R/hmk35k+i7hs8700J+sT/hW7+wGxu8UHvrSuoVv9qZ+UPqO4Vue6sfD7xq+3ec549F3Dt/wrd1g9N3Dt369HwW/f/i21/fD0A8A70Hf7KmZNQS8y6zvHH8QeOhzGwa+8Qc63dMPBN/8XX3X+EPBO8l3ST8WvMOb+l7pB4P3o+8Nfzh46Jc1IDz0SxoS3uWdXWf4Y8K7fJzTF/6g8M6TvgP6YeGZ9C83Lrw/fWj8keHb3EqjU/qh4dvcOqlP+rHhY9CHxB8d3v4O+MvyPgyzhoe3X+doYd7HIWl8+DCTfhsKXwG+wbIXGXkfi6c04KNc5D3mfSyOqcCHmvQR6GXgA53pj3kfDh34cPS++ErwYd7Zfc/vWEjB58uPS68FH3HSb33w1eAjTvqtB70cfLb8oPQ1bls+3cd4fvPqqPBh6dviV4A/3qp+/y53055lk7Sib4dfAX5/edtioYKq5YOMRl8Mf3Xx5+dpxl/aL1RQsxUgY9GXX9zdf9q8OezaLFRQsTUgzeQb2Otd1X9rBUe7ST9l+uyF4aNP+q0pvcESows3HaA1Fm0nvR298ow/dEFvhL8Mfndcaerjwk3WXFTYulUSzekN8JfA7x4u2w/Hy/cT9E2WGDVsnUN7+dr0C+Dv/vHtLfq/Z7wtFxw0ahWDg3xd+n6WGLVrlYLDy/1UtSfd0xKjZq0z8JGvRd/XEqNmrSJwmvR16Jec46+ertJP4BZsOlbrCLzoK9gvmfH3n94bbDpYKwXc6EvxF73U3/325eU/dnPqb0Zf8Gr0dT65GwJ+rbzXVd7U+icL/LPWHn7HSb9di58B/3CR96bipkO29uC7ym/X4Iv/kGbW2iPvO+m3+fTAJ60+8p3RL4Hfv928v85+G98pfM/0OfgL4KdPZa8f1E/8PmXJpuO2/rgHoF+Kv+STuw9/HXbvT/4cpmTTgSs46iHol+AvnPFTMjO+SL4X+iXn+LurSf5G5Rw/VXTMu5Dnqv50Rcc8yKR/ER/4cxUd8Sjy27P4Gb96df9Z5eLusaLDHWbSb8/QL5nx18dfstzlfWDbP3yZfKRJf4p+2Y9lr37+76eLV340m7vpHio62pEm/XaGv/Acf5M73V/fdBeVHetQ9MkzWzrj/3OlOONL5SO93idPbAn8zdM5/sTtTl5qCPhxJn3ytLiqf7XCAx5FPnlWS+D/9e3h/Js0LzQKfLF8DPrkSRV/d+58w8CPQZ88JYNvyy7cdFeVHvUA9Mkz4iPbZRUfd3f65AkBv7TiI+9MnzydZfA3v9zeSL/UT5Ufe1f65Nks/SbNw3/2v2q+nftWhaMf57sXy+A//PUw5+Xh+570yVNZ+FK/ufiyU3+pn6oAEOQLtlzc5VVBIMa9NIDPrYKBC33yNIDProaC/w3TgM+vikNz+eRJAL+iKhDO98cEfk1VJHzvigv8qupYeN4EHfiVVcFoOemT8QO/tjocbuudAL+6SiBOa5sBX1AlEpcVDYEvqRZKC/pk6MAXVY2l+WL1wBdWDcZaPhl3MXzvK1QUV03GeNInw+Z+9cXVszGVT0bNChUVqoZjOemTMTPja1SPx44+GTIrVFSpIpAVfTJiruorVZHIhj4ZL/C1qolkIZ8MV3pt2brVVDKQT0bLjK9XTab68slgDeC7Wlu2ajWdqp/ok7Ey42tWVaoyfTJU4KtWlaoufTLS4k/uzq9GqAgfmD4ZZ/GMP78aoSZ8Zfl69Mkwy1/qz65GKApfW74WfTJKzvEGVYF6VhX5ZIzAW1QD6nk1Jn0yRFaaNKncKalcPhkh8DZVsP6x4kmfDBB4o6po/1AhfTI+zvFWVeJ+XhF9Mjzg7aoG/r0C+mRwwBtWUfxbq+WTsQFvWU3xr62d9MnQgLetLvpj6+STgQFvXGX0Y6smfTIu4K2rzj61Qj4ZFvDm1Wffrpn0yaiAt88CPp8+GRTwDbKRz3y9T8YEfIus5HPokyEB3yYreuCjZyW/mD4ZD/CtMpJfTJ8MB/h2+dIngwG+YVbyi+iTsQDfMjP5BfTJUIBvmx99MhDgG2cn/8p7u2QcwLfOUv4l+mQYwLfPkh74yFnKn6VPxgC8R4byZ+mTIQDvkqX8GfpkBMD7ZCp/kj4ZAPBO2cqfuMpL9g+8V63lk90D71Zj+WTvwPtlLf8jfbJz4B0zlv+RPtk38K41pE/2DLxv1vLf6ZMdA++cufxX+mS/wLvXiD7ZK/D+2ctP7+2SnQIfoBbyqQbwIWpB/+MegY+RPXyyQ+CDBLxswKvWFfy0+tS0WMF8oUngs+sM/rjy2P7d7P8CPru+4PeXt6w7V6mO4K8u/vw8zfhL5UWF69UN/LQozebNYSe+qHC9+oE/G/DrAl61ruC5uKtYT/AnAn51fcLrLipcry7hF26aXgp42YLDs6iwWbHhWVTYrtjwLCpsV2z4swFfHPCqRYdniVGrgJcNeNUiw58M+EoBLxvwqgGvGvCyAa8a8KoBrxrwqgGvGvCqAS8b8KoBrxrwqgGvGvCqAS8b8KoBrxrwsgGvGvCqAa8a8KoBrxrwqgEvG/CqAa8a8LIBrxrwqgEvG/CqAa8a8KoBrxrwqgGvWiP4/dszt6sH3q0W8PefPh7/uZuvKgy8Ww3gvy47xvJjoWLGq2Z/jn9alIZzfLC4qlcNeNXawHNxFy9mvGqN4VlbNkyW8Pu3m4svvNRHzfR9/LTYJPBBs/3k7voN8FGz/eTu5m+/Ah81q0/ujkuP3bCadNx4O6ca8LKx0qRqwNMx4EXjHC9aO/jN6f+e9z83+yNj73/+MA34Ifc/f5gG/JD7nz9MA37I/c8fpgE/5P7nD9OAH3L/84dpwA+5//nDNOCH3P/8YRrwQ+5//jAN+CH3P3+YBvyQ+58/TCuCp8jZwb/6F8Nw26Yb73XbORsHfqBtAy+6beBFtw286LaBF9028KLbjgJPgQNeNOBFA1404EUDXjTgRQNeNOBFA140U/j9/IZJdbq72szvol4ts2EfV/v4aLTtw+7kLcbPZQm/yxlITtOduG7emGz6YDjsw91vXw77v3+x2fj01zXjoBjCX1/8YTR1pnvumU1Lu2EfdpPLtdmUz3qt6vKlfn95e5w9Rtm91B8OluM+BJnxdkdwWialU/jp7rBW7d9eLD8mNvDXm830d48Zn/Z0t0izzS8/KF3OeNNzvO1VveEJfmr5BUSX8NPrpd1VvR28qXvm+a9L+F7fx98cv+Fihf+wdfdzPIUPeNGAFw140YAXDXjRgBcNeNGAFw140YAXDXjRgBcNeNGAFw140YAXDXjRgBcNeNGAPxxupl/cvH6f+a3DzgP+cPxt9P3lbea3DjsP+MP0zZz//f74i8mmX5sLFfBTN/98+mYTM16rp6+4ZH3rsPOAf+j+9z8uH7+YY/ol5lABfzjesOD66bXe8rYFoQL+25dvjb91Hyzgn+5V8PBmPu9bh50HvGjAiwa8aMCLBrxowIsGvGjAiwa8aMCLBrxowIsGvGjAiwa8aMCLBrxowIv2f1d5XiZeljAfAAAAAElFTkSuQmCC" alt="plot of chunk unnamed-chunk-16"/> <img src="data:image/png;base64,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" alt="plot of chunk unnamed-chunk-16"/> <img src="data:image/png;base64,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" alt="plot of chunk unnamed-chunk-16"/> </p>

<p>Model AIC/BIC and mean residual deviance</p>

<pre><code class="r">AIC(credit.gam)
</code></pre>

<pre><code>## [1] 1787
</code></pre>

<pre><code class="r">BIC(credit.gam)
</code></pre>

<pre><code>## [1] 2196
</code></pre>

<pre><code class="r">credit.gam$deviance
</code></pre>

<pre><code>## [1] 1660
</code></pre>

<h4>In-sample fit performance</h4>

<pre><code class="r">pcut.gam &lt;- 0.08
prob.gam.in &lt;- predict(credit.gam, credit.train, type = &quot;response&quot;)
pred.gam.in &lt;- (prob.gam.in &gt;= pcut.gam) * 1
table(credit.train$Y, pred.gam.in, dnn = c(&quot;Observation&quot;, &quot;Prediction&quot;))
</code></pre>

<pre><code>##            Prediction
## Observation    0    1
##           0 3395  831
##           1   96  178
</code></pre>

<p>Misclassification rate is</p>

<pre><code class="r">mean(ifelse(credit.train$Y != pred.gam.in, 1, 0))
</code></pre>

<pre><code>## [1] 0.206
</code></pre>

<p>Training model AIC and BIC</p>

<pre><code class="r">AIC(credit.gam)
</code></pre>

<pre><code>## [1] 1787
</code></pre>

<pre><code class="r">BIC(credit.gam)
</code></pre>

<pre><code>## [1] 2196
</code></pre>

<h4>Search for optimal cut-off probability</h4>

<p>The following code does a grid search from pcut = 0.01 to pcut = 0.99 with the objective of minimizing overall cost in the training set. I am using an asymmetric cost function by assuming that giving out a bad loan cost 10 time as much as rejecting application from someone who can pay.</p>

<pre><code class="r"># define the searc grid from 0.01 to 0.20
searchgrid = seq(0.01, 0.2, 0.01)
# result.gam is a 99x2 matrix, the 1st col stores the cut-off p, the 2nd
# column stores the cost
result.gam = cbind(searchgrid, NA)
# in the cost function, both r and pi are vectors, r=truth, pi=predicted
# probability
cost1 &lt;- function(r, pi) {
    weight1 = 10
    weight0 = 1
    c1 = (r == 1) &amp; (pi &lt; pcut)  #logical vector - true if actual 1 but predict 0
    c0 = (r == 0) &amp; (pi &gt; pcut)  #logical vecotr - true if actual 0 but predict 1
    return(mean(weight1 * c1 + weight0 * c0))
}

for (i in 1:length(searchgrid)) {
    pcut &lt;- result.gam[i, 1]
    # assign the cost to the 2nd col
    result.gam[i, 2] &lt;- cost1(credit.train$Y, predict(credit.gam, type = &quot;response&quot;))
}
plot(result.gam, ylab = &quot;Cost in Training Set&quot;)
</code></pre>

<p><img src="data:image/png;base64,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" alt="plot of chunk unnamed-chunk-21"/> </p>

<pre><code class="r">index.min &lt;- which.min(result.gam[, 2])  #find the index of minimum value
result.gam[index.min, 2]  #min cost
</code></pre>

<pre><code>##        
## 0.3958
</code></pre>

<pre><code class="r">result.gam[index.min, 1]  #optimal cutoff probability
</code></pre>

<pre><code>## searchgrid 
##       0.09
</code></pre>

<h4>Out-of-sample fit performance</h4>

<pre><code class="r">pcut &lt;- result.gam[index.min, 1]
prob.gam.out &lt;- predict(credit.gam, credit.test, type = &quot;response&quot;)
pred.gam.out &lt;- (prob.gam.out &gt;= pcut) * 1
table(credit.test$Y, pred.gam.out, dnn = c(&quot;Observation&quot;, &quot;Prediction&quot;))
</code></pre>

<pre><code>##            Prediction
## Observation   0   1
##           0 393  81
##           1  17   9
</code></pre>

<p>mis-classifciation rate is</p>

<pre><code class="r">mean(ifelse(credit.test$Y != pred.gam.out, 1, 0))
</code></pre>

<pre><code>## [1] 0.196
</code></pre>

<p>Cost associated with misclassification is</p>

<pre><code class="r">creditcost(credit.test$Y, pred.gam.out)
</code></pre>

<pre><code>## [1] 0.502
</code></pre>

<p><a href="#content">go to top</a></p>

<hr/>

<h3><a id="da"></a> Discriminant Analysis</h3>

<p>Linear Discriminant Analysis (LDA) (in-sample and out-of-sample performance measure) is illustrated here. The following illustrate the usage of an arbitrary cut off probability.</p>

<h4>In-sample</h4>

<pre><code class="r">credit.train$Y = as.factor(credit.train$Y)
credit.lda &lt;- lda(Y ~ ., data = credit.train)
prob.lda.in &lt;- predict(credit.lda, data = credit.train)
pcut.lda &lt;- 0.15
pred.lda.in &lt;- (prob.lda.in$posterior[, 2] &gt;= pcut.lda) * 1
table(credit.train$Y, pred.lda.in, dnn = c(&quot;Obs&quot;, &quot;Pred&quot;))
</code></pre>

<pre><code>##    Pred
## Obs    0    1
##   0 3880  346
##   1  155  119
</code></pre>

<pre><code class="r">mean(ifelse(credit.train$Y != pred.lda.in, 1, 0))
</code></pre>

<pre><code>## [1] 0.1113
</code></pre>

<h4>Out-of-sample</h4>

<pre><code class="r">lda.out &lt;- predict(credit.lda, newdata = credit.test)
cut.lda &lt;- 0.15
pred.lda.out &lt;- as.numeric((lda.out$posterior[, 2] &gt;= cut.lda))
table(credit.test$Y, pred.lda.out, dnn = c(&quot;Obs&quot;, &quot;Pred&quot;))
</code></pre>

<pre><code>##    Pred
## Obs   0   1
##   0 436  38
##   1  20   6
</code></pre>

<pre><code class="r">mean(ifelse(credit.test$Y != pred.lda.out, 1, 0))
</code></pre>

<pre><code>## [1] 0.116
</code></pre>

<pre><code class="r">creditcost(credit.test$Y, pred.lda.out)
</code></pre>

<pre><code>## [1] 0.476
</code></pre>

<p><a href="#content">go to top</a></p>

<hr/>

<h3><a id="nnet"></a> Neural Networks Models</h3>

<p>Neural Networks method (in-sample and out-of-sample performance measure) is illustrated here. The package <a href="http://cran.r-project.org/web/packages/nnet/nnet.pdf"><strong>nnet</strong></a> is used for this purpose.</p>

<p><strong>Note</strong>: </p>

<ul>
<li>For classification problems with nnet you need to code the response to <em>factor</em> first. In addition you want to add type = &ldquo;class&rdquo; for <em>predict()</em>  function. </li>
<li>For regression problems add lineout = TRUE when training model</li>
</ul>

<pre><code class="r">Boston.nnet &lt;- nnet(medv ~ ., size = 4, data = Boston, linout = TRUE)
</code></pre>

<h4>Training</h4>

<pre><code class="r">library(nnet)
credit.train$Y = as.factor(credit.train$Y)
caseweights = ifelse(credit.train$Y == 1, 10, 1)
credit.nnet &lt;- nnet(Y ~ ., data = credit.train, size = 4, weights = caseweights)
</code></pre>

<pre><code>## # weights:  249
## initial  value 4754.566749 
## iter  10 value 3555.080569
## iter  20 value 3199.961198
## iter  30 value 2824.977389
## iter  40 value 2653.640139
## iter  50 value 2544.158576
## iter  60 value 2423.249152
## iter  70 value 2344.080508
## iter  80 value 2285.466210
## iter  90 value 2264.020575
## iter 100 value 2262.374599
## final  value 2262.374599 
## stopped after 100 iterations
</code></pre>

<h4>Out-of-sample Testing</h4>

<pre><code class="r">pred.nnet = predict(credit.nnet, credit.test, type = &quot;class&quot;)
table(credit.test$Y, pred.nnet, dnn = c(&quot;Observation&quot;, &quot;Prediction&quot;))
</code></pre>

<pre><code>##            Prediction
## Observation   0   1
##           0 438  36
##           1  23   3
</code></pre>

<pre><code class="r">mean(ifelse(credit.test$Y != pred.nnet, 1, 0))
</code></pre>

<pre><code>## [1] 0.118
</code></pre>

<pre><code class="r">creditcost(credit.test$Y, pred.nnet)
</code></pre>

<pre><code>## [1] 0.532
</code></pre>

<p><a href="#content">go to top</a></p>

<h3><a id="svm"></a> Support Vector Machine (SVM)</h3>

<p>SVM is probably one of the best off-the-shelf classifiers for many of problems. It handles nonlinearity, is well regularized (avoids overfitting), have few parameters, and fast for large number of observations. It can be adapted to handle regression problems as well. You can read more about SVM in Chapter 12 of the textbook. </p>

<p>The R package e1071 offers an interface to the most popular svm implementation libsvm. You should read more about the usage of the package in this short tutorial (<a href="http://cran.r-project.org/web/packages/e1071/vignettes/svmdoc.pdf">http://cran.r-project.org/web/packages/e1071/vignettes/svmdoc.pdf</a>).</p>

<pre><code class="r">install.packages(&quot;e1071&quot;)
</code></pre>

<p>The class.weights option can be used to handle asymmetric cost in our credit data. The other 2 parameters are cost and gamma, the default values are used here.</p>

<pre><code class="r">library(e1071)
credit.train$Y = as.factor(credit.train$Y)
weight1 = 0.93
m = svm(Y ~ ., data = credit.train, class.weights = c(`1` = weight1, `0` = 1 - 
    weight1), cost = 1, gamma = 1/length(credit.train))
pred.svm = predict(m, credit.test)
table(credit.test$Y, pred.svm, dnn = c(&quot;Observation&quot;, &quot;Prediction&quot;))
</code></pre>

<pre><code>##            Prediction
## Observation   0   1
##           0 399  75
##           1  16  10
</code></pre>

<pre><code class="r">creditcost(credit.test$Y, pred.svm)
</code></pre>

<pre><code>## [1] 0.47
</code></pre>

<p><a href="#content">go to top</a></p>

<h3><a id="compare"></a> Performance Comparisons</h3>

<p>At last, after fitting several models, you may want to compare their in-sample and out-of-sample performances. The performance measures are illustrated in previous sections. In your report, you may want to put them in some table format. Note that not all measures are applicable. For example, I didn&#39;t find AIC/BIC or deviance for LDA models and Neural Network models. For tree models, <em>tree</em> package can give you mean residual deviance but not with <em>rpart</em> package. If you find either one of them, I would be interested to know.</p>

<h4>In-sample</h4>

<p>You may compare the following</p>

<ul>
<li>AIC or BIC</li>
<li>Mean Residual Deviance (for binary response) or Mean Square Error (for continuous response)</li>
<li>Cost (asymmetric or symmetric)</li>
<li>Misclassification Rate</li>
<li>ROC curve or Area Under the Curve (AUC)</li>
</ul>

<h4>Out-of-sample</h4>

<ul>
<li>Cost</li>
<li>Misclassification Rate</li>
<li>ROC curve or Area Under the Curve (AUC)</li>
</ul>

<p><a href="#content">go to top</a></p>

<h3><a id="german"></a> Starter code for German credit scoring</h3>

<p>Refer to <a href="http://archive.ics.uci.edu/ml/datasets/Statlog+(German+Credit+Data)">http://archive.ics.uci.edu/ml/datasets/Statlog+(German+Credit+Data)</a>) for variable description. Notice that &ldquo;It is worse to class a customer as good when they are bad (weight = 5), than it is to class a customer as bad when they are good (weight = 1).&rdquo; Define your cost function accordingly!</p>

<pre><code class="r">install.packages(&quot;caret&quot;)
</code></pre>

<pre><code class="r">library(caret)  #this package contains the german data with its numeric format
data(GermanCredit)
</code></pre>

<p><a href="#content">go to top</a></p>

</body>

</html>

